# Vertex AI to OpenAI API Adapter

This project provides a lightweight adapter to convert OpenAI API requests to Google's Vertex AI API. It allows you to use OpenAI-compatible clients and libraries with Google's powerful Generative Models (like Gemini) without any code changes on the client side.

This adapter is implemented in Python using the Flask framework.

## âœ¨ Features

- ğŸ”„ **Protocol Translation**: Translates OpenAI Chat Completions API requests to Vertex AI `generate_content` format.
- ğŸš€ **Model Mapping**: Maps common OpenAI model names (e.g., `gpt-4`, `gpt-3.5-turbo`) to specified Vertex AI models (e.g., `gemini-2.5-pro`).
- ğŸ’¬ **Basic Chat**: Supports standard request/response chat.
- ğŸŒŠ **Streaming**: Supports real-time streaming of responses.
- ğŸ› ï¸ **Function Calling**: Supports OpenAI's function calling/tools format.
- ğŸ‘ï¸ **Vision Support**: Supports multimodal requests with images (both URL and base64 encoded).
- models-listing **Models Listing**: Provides an endpoint (`/v1/models`) that lists available models, ensuring compatibility with clients that perform this check.

## ğŸ› ï¸ Prerequisites

Before you begin, ensure you have the following installed:

1.  **Python**: Version 3.8 or higher.
2.  **Google Cloud SDK**: The `gcloud` command-line tool. You can install it from [here](https://cloud.google.com/sdk/docs/install).
3.  **pip**: Python's package installer.

## âš™ï¸ Setup & Deployment

Follow these steps to get the adapter up and running.

### 1. Clone the Repository

Clone this project to your local machine.

```bash
# This step is assumed to be done.
# git clone <your-repository-url>
# cd vertex-openai-adapter
```

### 2. Install Dependencies

Install the required Python packages using `pip`.

```bash
pip install -r requirements.txt
```

### 3. Authenticate with Google Cloud

You need to authenticate your environment to allow the adapter to make calls to the Vertex AI API. The recommended way is to use Application Default Credentials (ADC).

Run the following command and follow the instructions to log in with your Google account:

```bash
gcloud auth application-default login
```

This will store your credentials in a local file that the Vertex AI SDK can automatically find.

### 4. Configure Environment (Optional)

The adapter can be configured via environment variables.

-   `PROJECT_ID`: Your Google Cloud Project ID. Defaults to `cursor-use-api`.
-   `LOCATION`: The Google Cloud region for Vertex AI. Defaults to `us-central1`.
-   `HTTPS_PROXY`: If you are in a restricted network environment, you may need to set a proxy. Example: `http://127.0.0.1:7890`.

### 5. Run the Adapter

Start the Flask server. The following command ensures that any potentially incorrect global `GOOGLE_APPLICATION_CREDENTIALS` variable is ignored (preferring the ADC from step 3) and sets a proxy if you need one.

**On Windows (PowerShell):**

```powershell
$env:GOOGLE_APPLICATION_CREDENTIALS=""; $env:HTTPS_PROXY="http://127.0.0.1:7890"; python simplest.py
```

**On Linux/macOS:**

```bash
GOOGLE_APPLICATION_CREDENTIALS="" HTTPS_PROXY="http://127.0.0.1:7890" python simplest.py
```

The server will start on `http://127.0.0.1:5000` by default.

## ğŸ”Œ Usage

Once the server is running, you can configure your OpenAI-compatible client to use it.

-   **API Base URL / Endpoint**: `http://127.0.0.1:5000/v1`
    *(Note: Some clients may require you to enter `http://127.0.0.1:5000` and they will add the `/v1` suffix automatically.)*
-   **API Key**: Any string will work (e.g., `sk-12345`). The adapter does not validate it.
-   **Model**: Use any of the model names mapped in the script, such as `gpt-4`, `gpt-4-turbo`, or `gpt-4o`.

You can now send requests from your client, and they will be processed by Vertex AI's Gemini model.

## ç‰ˆæœ¬å†å²

- v0.0.1ï¼šåŸºæœ¬åŠŸèƒ½ï¼Œæ”¯æŒç®€å•å¯¹è¯å’Œæµå¼ä¼ è¾“
- v0.0.2ï¼šæ·»åŠ å‡½æ•°è°ƒç”¨å’Œè§†è§‰æ¨¡å‹æ”¯æŒ

## æ¨¡å‹æ˜ å°„

| OpenAI æ¨¡å‹åç§° | Vertex AI æ¨¡å‹åç§° |
|---------------|-----------------|
| gpt-4o | gemini-2.5-pro |
| gpt-4-vision-preview | gemini-2.5-pro-vision |
| gpt-4-turbo | gemini-2.5-pro |
| gpt-4 | gemini-2.5-pro |
| gpt-3.5-turbo | gemini-2.5-flash |

## API ä½¿ç”¨ç¤ºä¾‹

### æ ‡å‡†èŠå¤©å®Œæˆï¼ˆéæµå¼ï¼‰

```python
import requests
import json

url = "http://localhost:5001/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer sk-test123456789"  # ä»»æ„å¯†é’¥ï¼Œå®é™…ä¸ä¼šéªŒè¯
}
data = {
    "model": "gpt-4o",  # å°†æ˜ å°„åˆ° gemini-2.5-pro
    "messages": [
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
    ]
}

response = requests.post(url, headers=headers, json=data)
print(json.dumps(response.json(), indent=2, ensure_ascii=False))
```

### æµå¼ä¼ è¾“èŠå¤©å®Œæˆ

```python
import requests
import json

url = "http://localhost:5001/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer sk-test123456789"  # ä»»æ„å¯†é’¥ï¼Œå®é™…ä¸ä¼šéªŒè¯
}
data = {
    "model": "gpt-4o",  # å°†æ˜ å°„åˆ° gemini-2.5-pro
    "messages": [
        {"role": "user", "content": "è¯·ç”¨è¯—æ­Œå½¢å¼æè¿°æ˜¥å¤©ã€‚"}
    ],
    "stream": True
}

response = requests.post(url, headers=headers, json=data, stream=True)
for line in response.iter_lines():
    if line:
        line_text = line.decode('utf-8')
        if line_text.startswith("data: "):
            content = line_text[6:]
            if content == "[DONE]":
                break
            try:
                chunk = json.loads(content)
                if "choices" in chunk and chunk["choices"]:
                    delta = chunk["choices"][0].get("delta", {})
                    if "content" in delta:
                        print(delta["content"], end="", flush=True)
            except json.JSONDecodeError:
                pass
```

### å‡½æ•°è°ƒç”¨ç¤ºä¾‹

```python
import requests
import json

url = "http://localhost:5001/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer sk-test123456789"
}

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–ç‰¹å®šä½ç½®çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"],
                        "description": "æ¸©åº¦å•ä½"
                    }
                },
                "required": ["location"]
            }
        }
    }
]

data = {
    "model": "gpt-4o",
    "messages": [
        {"role": "user", "content": "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}
    ],
    "tools": tools
}

response = requests.post(url, headers=headers, json=data)
result = response.json()
print(json.dumps(result, indent=2, ensure_ascii=False))
```

### è§†è§‰æ¨¡å‹ç¤ºä¾‹

```python
import requests
import json
import base64

# è¯»å–å›¾åƒæ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
with open("test_images/test_image.jpg", "rb") as image_file:
    base64_image = base64.b64encode(image_file.read()).decode('utf-8')

url = "http://localhost:5001/v1/chat/completions"
headers = {
    "Content-Type": "application/json",
    "Authorization": "Bearer sk-test123456789"
}

data = {
    "model": "gpt-4-vision-preview",  # å°†æ˜ å°„åˆ° gemini-2.5-pro-vision
    "messages": [
        {
            "role": "user", 
            "content": [
                {"type": "text", "text": "è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆå†…å®¹ï¼Ÿè¯·è¯¦ç»†æè¿°ã€‚"},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                }
            ]
        }
    ]
}

response = requests.post(url, headers=headers, json=data)
result = response.json()
print(json.dumps(result, indent=2, ensure_ascii=False))
```

## æµ‹è¯•è„šæœ¬

é¡¹ç›®åŒ…å«å¤šä¸ªæµ‹è¯•è„šæœ¬ï¼Œç”¨äºéªŒè¯é€‚é…å™¨çš„å„ç§åŠŸèƒ½ï¼š

- `test_client.py`ï¼šæµ‹è¯•åŸºæœ¬çš„èŠå¤©åŠŸèƒ½
- `test_vertexai_direct.py`ï¼šç›´æ¥æµ‹è¯•Vertex AI API
- `test_function_calling.py`ï¼šæµ‹è¯•å‡½æ•°è°ƒç”¨åŠŸèƒ½
- `test_vision.py`ï¼šæµ‹è¯•è§†è§‰æ¨¡å‹åŠŸèƒ½
- `run_all_tests.py`ï¼šè¿è¡Œæ‰€æœ‰æµ‹è¯•

è¦è¿è¡Œæµ‹è¯•ï¼Œè¯·ç¡®ä¿é€‚é…å™¨æ­£åœ¨è¿è¡Œï¼Œç„¶åæ‰§è¡Œï¼š

```bash
python run_all_tests.py
```

## é™åˆ¶

- ç›®å‰ä»…æ”¯æŒåŸºæœ¬çš„èŠå¤©å®ŒæˆåŠŸèƒ½
- ä»¤ç‰Œè®¡æ•°æ˜¯ä¼°ç®—çš„ï¼Œä¸ç²¾ç¡®
- ä¸æ”¯æŒåµŒå…¥ï¼ˆembeddingsï¼‰æˆ–ç¼–è¾‘åŠŸèƒ½

## è®¸å¯è¯

MIT

## è´¡çŒ®

æ¬¢è¿æäº¤PRå’Œé—®é¢˜æŠ¥å‘Šï¼ 